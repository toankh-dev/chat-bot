# ğŸ¤– Multi-Agent Chatbot

> **Há»‡ thá»‘ng chatbot thÃ´ng minh cháº¡y hoÃ n toÃ n trÃªn Local vá»›i HuggingFace Models**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-ready-brightgreen.svg)](https://www.docker.com/)

---

## ğŸ¯ Tá»•ng Quan

Há»‡ thá»‘ng Multi-Agent Chatbot sá»­ dá»¥ng:
- ğŸ¤— **HuggingFace Models** (StableLM-7B, MiniLM) - Miá»…n phÃ­, cháº¡y local
- ğŸ¦œ **LangChain** - Agent orchestration framework
- â˜ï¸ **LocalStack** - AWS services mock (S3, DynamoDB, Secrets Manager)
- ğŸ—„ï¸ **ChromaDB** - Vector database
- ğŸ® **Discord** - Data source (thay tháº¿ GitLab/Slack/Backlog)

### âš¡ TÃ­nh NÄƒng ChÃ­nh

- âœ… **Multi-Agent Architecture**: Orchestrator phá»‘i há»£p cÃ¡c agent chuyÃªn biá»‡t
- âœ… **RAG (Retrieval-Augmented Generation)**: Truy xuáº¥t context tá»« vector database
- âœ… **Conversation Memory**: LÆ°u trá»¯ lá»‹ch sá»­ chat trong DynamoDB
- âœ… **Discord Integration**: Fetch vÃ  phÃ¢n tÃ­ch Discord messages
- âœ… **Code Review**: PhÃ¢n tÃ­ch code snippets
- âœ… **Report Generation**: Táº¡o bÃ¡o cÃ¡o tá»« dá»¯ liá»‡u
- âœ… **100% Local**: KhÃ´ng cáº§n AWS, data khÃ´ng rá»i khá»i mÃ¡y

### ğŸ’° Chi PhÃ­

| AWS Bedrock (Cloud) | Local Setup (Báº£n nÃ y) |
|--------------------|-----------------------|
| $350-1,400/thÃ¡ng | **$0** âœ… |

---

## ğŸš€ Quick Start

### Äiá»u Kiá»‡n TiÃªn Quyáº¿t

- Docker Desktop (4GB+ RAM allocated)
- Python 3.11+
- 16GB+ RAM (recommend 32GB)
- 50GB+ disk space

### 3 BÆ°á»›c Setup

#### 1. Clone & Configure

```bash
# Clone repository
git clone <your-repo-url>
cd chat-bot

# Copy environment template
cp .env.example .env

# Edit .env - Add Discord credentials (optional)
USE_DISCORD=true
DISCORD_BOT_TOKEN=your_bot_token
DISCORD_CHANNEL_IDS=your_channel_ids
```

#### 2. Start Services

```bash
# Start all services (first time: download models ~15GB)
docker-compose up -d

# Wait for models to download (10-30 minutes)
docker-compose logs -f llm-service

# Setup LocalStack resources
python scripts/setup_localstack.py
```

#### 3. Test Chatbot

```bash
# Health check
curl http://localhost:8000/health

# Send test message
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello!", "conversation_id": "test-1"}'
```

âœ… **Done!** Chatbot Ä‘ang cháº¡y táº¡i `http://localhost:8000`

---

## ğŸ“š Documentation

| Document | Description |
|----------|-------------|
| **[START_HERE.md](START_HERE.md)** | â­ Báº¯t Ä‘áº§u tá»« Ä‘Ã¢y! Quick start guide |
| **[LOCAL_SETUP_GUIDE.md](LOCAL_SETUP_GUIDE.md)** | HÆ°á»›ng dáº«n setup chi tiáº¿t |
| **[LOCAL_ARCHITECTURE.md](LOCAL_ARCHITECTURE.md)** | Kiáº¿n trÃºc há»‡ thá»‘ng |
| **[LOCALSTACK_DOCKER.md](LOCALSTACK_DOCKER.md)** | LocalStack Docker setup |
| **[DISCORD_SETUP_GUIDE.md](DISCORD_SETUP_GUIDE.md)** | Setup Discord bot (5 phÃºt) |
| **[DISCORD_INTEGRATION.md](DISCORD_INTEGRATION.md)** | Discord integration code |

> **Note**: ThÆ° má»¥c `docs/` chá»©a tÃ i liá»‡u AWS Bedrock (legacy) - PhiÃªn báº£n cloud cÅ©, tá»‘n phÃ­

---

## ğŸ—ï¸ Architecture

```
User Request
    â†“
FastAPI App (Port 8000)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ORCHESTRATOR AGENT (LangChain) â”‚
â”‚  - PhÃ¢n tÃ­ch cÃ¢u há»i            â”‚
â”‚  - Láº­p káº¿ hoáº¡ch execution       â”‚
â”‚  - Phá»‘i há»£p cÃ¡c tools           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”œâ”€â”€â–º Vector Store (ChromaDB) - RAG retrieval
    â”œâ”€â”€â–º LLM Service (StableLM-7B) - Text generation
    â”œâ”€â”€â–º Embedding Service (MiniLM) - Text embeddings
    â”œâ”€â”€â–º Discord Tool - Fetch messages
    â”œâ”€â”€â–º Report Tool - Generate reports
    â””â”€â”€â–º Code Review Tool - Analyze code
```

### Tech Stack

| Component | Technology |
|-----------|-----------|
| **LLM** | StabilityAI/stablelm-zephyr-3b |
| **Embeddings** | sentence-transformers/all-MiniLM-L12-v2 |
| **Framework** | LangChain + FastAPI |
| **Vector DB** | ChromaDB |
| **Storage** | LocalStack S3 + DynamoDB |
| **Database** | PostgreSQL + Redis |
| **Orchestration** | Docker Compose |

---

## ğŸ“Š Service Ports

| Service | Port | URL |
|---------|------|-----|
| Main App | 8000 | http://localhost:8000 |
| ChromaDB | 8001 | http://localhost:8001 |
| Embedding Service | 8002 | http://localhost:8002 |
| LLM Service | 8003 | http://localhost:8003 |
| LocalStack | 4566 | http://localhost:4566 |
| PostgreSQL | 5432 | localhost:5432 |
| Redis | 6379 | localhost:6379 |

---

## ğŸ® Discord Integration (Recommended!)

Thay vÃ¬ GitLab/Slack/Backlog (phá»©c táº¡p, tá»‘n phÃ­), dÃ¹ng **Discord** (miá»…n phÃ­, 5 phÃºt setup):

### Táº¡i sao Discord?

- âœ… **Miá»…n phÃ­** - KhÃ´ng cáº§n paid plan
- âœ… **Dá»… setup** - Chá»‰ 5 phÃºt
- âœ… **Rich API** - Messages, threads, reactions, embeds
- âœ… **Webhook support** - Realtime notifications

### Quick Setup

```bash
# 1. Táº¡o Discord bot (5 phÃºt)
# Xem: DISCORD_SETUP_GUIDE.md

# 2. Add credentials to .env
DISCORD_BOT_TOKEN=MTIzNDU2...
DISCORD_CHANNEL_IDS=111111,222222

# 3. Fetch data
python scripts/run_data_fetcher.py --source discord

# 4. Build index
python scripts/build_vector_index.py
```

Xem chi tiáº¿t: [DISCORD_SETUP_GUIDE.md](DISCORD_SETUP_GUIDE.md)

---

## ğŸ› ï¸ Usage Examples

### Chat API

```bash
# Simple chat
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "What are the recent Discord messages?",
    "conversation_id": "conv-123"
  }'

# Response:
{
  "conversation_id": "conv-123",
  "answer": "Based on recent messages...",
  "sources": ["discord_msg_1", "discord_msg_2"],
  "processing_time": 4.2
}
```

### Search Knowledge Base

```bash
# Search for context
curl "http://localhost:8000/search?query=bug&limit=5"

# Response:
{
  "results": [
    {
      "content": "Bug report from Discord...",
      "metadata": {"source": "discord", "channel": "dev"},
      "score": 0.89
    }
  ]
}
```

### View Conversation History

```bash
# Get conversation
curl http://localhost:8000/conversation/conv-123

# Response:
{
  "conversation_id": "conv-123",
  "messages": [
    {"role": "user", "content": "Hello"},
    {"role": "assistant", "content": "Hi! How can I help?"}
  ]
}
```

---

## ğŸ”§ Development

### Project Structure

```
chat-bot/
â”œâ”€â”€ app/                      # Main application
â”‚   â”œâ”€â”€ main.py              # FastAPI app
â”‚   â”œâ”€â”€ agents/              # LangChain agents
â”‚   â”œâ”€â”€ tools/               # Agent tools
â”‚   â”œâ”€â”€ llm/                 # LLM wrappers
â”‚   â””â”€â”€ stores/              # Data stores
â”œâ”€â”€ services/                # Microservices
â”‚   â”œâ”€â”€ embedding/           # Embedding service
â”‚   â””â”€â”€ llm/                 # LLM service
â”œâ”€â”€ scripts/                 # Utility scripts
â”‚   â”œâ”€â”€ setup_localstack.py
â”‚   â”œâ”€â”€ run_data_fetcher.py
â”‚   â””â”€â”€ build_vector_index.py
â”œâ”€â”€ lambda/                  # AWS Lambda functions (for cloud deployment)
â”œâ”€â”€ docs/                    # AWS Bedrock documentation (legacy)
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

### Local Development

```bash
# Install dependencies
pip install -r requirements.txt

# Run app locally (without Docker)
uvicorn app.main:app --reload --port 8000

# Run tests
pytest tests/
```

### Adding New Tools

```python
# app/tools/my_tool.py
from langchain.tools import BaseTool

class MyTool(BaseTool):
    name = "my_tool"
    description = "Tool description for LLM"

    def _run(self, query: str) -> str:
        # Tool logic
        return "Result"
```

---

## ğŸ› Troubleshooting

### Models Not Downloading

```bash
# Check internet connection
ping huggingface.co

# Check Docker logs
docker-compose logs llm-service

# Restart service
docker-compose restart llm-service
```

### LocalStack Connection Error

```bash
# Verify LocalStack running
curl http://localhost:4566/_localstack/health

# Check .env configuration
cat .env | grep LOCALSTACK

# Restart LocalStack
docker-compose restart localstack
```

### ChromaDB Error

```bash
# Check ChromaDB status
curl http://localhost:8001/api/v1/heartbeat

# Clear and rebuild
docker-compose down chromadb
docker volume rm chat-bot_chroma-data
docker-compose up -d chromadb
python scripts/build_vector_index.py
```

---

## ğŸ“ˆ Performance

### Resource Usage

| Service | RAM | CPU | Disk |
|---------|-----|-----|------|
| LLM (StableLM-7B) | ~8GB | 2-4 cores | ~14GB |
| Embedding (MiniLM) | ~1GB | 1 core | ~500MB |
| ChromaDB | ~500MB | 1 core | Varies |
| PostgreSQL | ~200MB | 1 core | ~100MB |
| Redis | ~100MB | 1 core | ~50MB |
| **Total** | **~10GB** | **5-7 cores** | **~15GB** |

### Response Times

| Query Type | CPU | GPU (if available) |
|-----------|-----|---------------------|
| Simple QA | 5-10s | 2-3s |
| RAG Query | 8-15s | 3-5s |
| Code Review | 10-20s | 4-7s |

---

## ğŸ” Security

- âœ… All credentials in `.env` (gitignored)
- âœ… No data sent to external APIs
- âœ… LocalStack for AWS mock (no cloud)
- âœ… Network isolated via Docker

---

## ğŸ“ License

MIT License - See [LICENSE](LICENSE) file

---

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing`)
5. Open Pull Request

---

## ğŸ†˜ Support

- **Documentation**: See docs above
- **Issues**: Create GitHub issue vá»›i logs
- **Discord Setup**: See [DISCORD_SETUP_GUIDE.md](DISCORD_SETUP_GUIDE.md)
- **LocalStack**: See [LOCALSTACK_DOCKER.md](LOCALSTACK_DOCKER.md)

---

## ğŸ‰ Status

**Current Version**: v1.0.0 (Local Setup Complete)

- âœ… Core infrastructure implemented
- âœ… Multi-agent orchestration working
- âœ… Discord integration ready
- âœ… LocalStack configured
- âœ… Vector search functional
- â³ UI in development (optional)

---

**Built with â¤ï¸ using Open Source**
